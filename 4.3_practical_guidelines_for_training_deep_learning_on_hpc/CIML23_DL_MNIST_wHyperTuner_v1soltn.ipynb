{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST exercise with hypertuning\n",
    "**Goal: Introduction to Keras Tuner object**\n",
    "\n",
    "**Exercise:**\n",
    "    \n",
    "1. Review the steps of the code in this notebook\n",
    "2. Look for the build_model and build_model_hp functions \n",
    "3. run the notebook, review the summary of hypertuning results\n",
    "4. change the build_model functions and add one or two more parameters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_tuner\n",
      "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (21.3)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->keras_tuner) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras_tuner) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/p4rodrig/.local/lib/python3.8/site-packages (from requests->keras_tuner) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras_tuner) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/p4rodrig/.local/lib/python3.8/site-packages (from requests->keras_tuner) (1.26.16)\n",
      "Installing collected packages: kt-legacy, keras_tuner\n",
      "Successfully installed keras_tuner-1.3.5 kt-legacy-1.0.5\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='23.1.2'),)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_tuner --prefix ~/.local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------- IMPORT STATEMENTS ---------------\n",
    "import numpy as np\n",
    "np.random.seed(1)  # for reproducibility\n",
    " \n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "\n",
    "import keras_tuner as kt    #<<----- NEW import\n",
    "#---------------------------------------------\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (1000, 28, 28, 1)\n",
      "X test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load MNIST data from Keras datasets\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train=X_train[0:1000,]  #only need smaller subset to get good results\n",
    "Y_train=Y_train[0:1000,]\n",
    "\n",
    "# --------- Reshape input data, b/c Keras expects N-3D images (ie 4D matrix)\n",
    "X_train = X_train[:,:,:,np.newaxis]\n",
    "X_test  = X_test[:,:,:,np.newaxis]\n",
    "\n",
    "#Scale 0 to 1  - or should we not scale\n",
    "X_train = X_train/255.0\n",
    "X_test  = X_test/255.0\n",
    "\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
    "Y_test  = keras.utils.to_categorical(Y_test,  10)\n",
    "\n",
    "# ------------- End loading and preparing data --------------\n",
    "print('X train shape:', X_train.shape) \n",
    "print('X test shape:', X_test.shape) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notice here is a new function for the hypertuner that wraps around the build-model function\n",
    "\n",
    "'hp' is an argument is this function\n",
    "\n",
    "hp is a hyperparameter tuner object\n",
    "\n",
    "See https://keras.io/keras_tuner/\n",
    "\n",
    "After running through the notebook, add a new parameter \n",
    "\n",
    "For example, add a set of choices for either 'relu' or 'elu' activation\n",
    "\n",
    "For details see here\n",
    "https://keras.io/api/keras_tuner/hyperparameters/#choice-method\n",
    "and here\n",
    "https://keras.io/api/layers/activations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_hp(hp): \n",
    "  hp_numfilters    = hp.Int('hpnumfilters',min_value=8,max_value=32,step=4)\n",
    "  #your variable name         ^^^ the parameter name in the hp object\n",
    "\n",
    "  # For Step4  -------- Add code here (and see below) --------------------\n",
    "  #  add a new parameter object; for example\n",
    "  hp_Activation    = hp.Choice('hpActivation', values=['relu','elu']) \n",
    "    \n",
    "  return build_model(hp_numfilters,hp_Activation)   #<<---- dont forget to pass the new choices to build_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------Set up Model ---------------------\n",
    "def build_model(numfilters,activation_choice):   #<<------add code: if you add parameters to search, add them to the argument \n",
    "                                      #            list and change code to use those arguments\n",
    "    mymodel = keras.models.Sequential()\n",
    "    mymodel.add(keras.layers.Convolution2D(numfilters, \n",
    "                                       (3, 3),\n",
    "                                       strides=1,  \n",
    "                                       data_format=\"channels_last\",\n",
    "                                       activation=activation_choice, #<<<< ---- add code\n",
    "                                       input_shape=(28,28,1))) \n",
    "    mymodel.add(keras.layers.Convolution2D(numfilters, \n",
    "                                       (3, 3),\n",
    "                                       strides=1,  \n",
    "                                       data_format=\"channels_last\",\n",
    "                                       activation=activation_choice))\n",
    "    mymodel.add(keras.layers.MaxPooling2D(pool_size=(2,2),strides=2,data_format=\"channels_last\"))\n",
    "    mymodel.add(keras.layers.Flatten())            #reorganize 2DxFilters output into 1D\n",
    "  \n",
    "    #----------------Now add final classification layers\n",
    "    mymodel.add(keras.layers.Dense(32, activation=activation_choice))   \n",
    "    mymodel.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    print('assemble model done')\n",
    "    \n",
    "    # --------- Now configure model algorithm -----\n",
    "    mymodel.compile(loss='categorical_crossentropy',\n",
    "               optimizer=keras.optimizers.Adam(learning_rate=0.005),  \n",
    "               metrics=['accuracy'])\n",
    "\n",
    "    return mymodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hypertuner object so that it will build model and run fit\n",
    "https://keras.io/keras_tuner/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 Complete [00h 00m 20s]\n",
      "val_accuracy: 0.8914599895477295\n",
      "\n",
      "Best val_accuracy So Far: 0.9150399923324585\n",
      "Total elapsed time: 00h 03m 58s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in My_HP_trials/hyperbandtest\n",
      "Showing 5 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0006 summary\n",
      "Hyperparameters:\n",
      "hpnumfilters: 28\n",
      "hpActivation: relu\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.9150399923324585\n",
      "\n",
      "Trial 0007 summary\n",
      "Hyperparameters:\n",
      "hpnumfilters: 32\n",
      "hpActivation: relu\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.9109999895095825\n",
      "\n",
      "Trial 0011 summary\n",
      "Hyperparameters:\n",
      "hpnumfilters: 16\n",
      "hpActivation: relu\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.9091600060462952\n",
      "\n",
      "Trial 0001 summary\n",
      "Hyperparameters:\n",
      "hpnumfilters: 20\n",
      "hpActivation: relu\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.9067600131034851\n",
      "\n",
      "Trial 0012 summary\n",
      "Hyperparameters:\n",
      "hpnumfilters: 24\n",
      "hpActivation: relu\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.9061800003051758\n"
     ]
    }
   ],
   "source": [
    "myES_function = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5) #patience before stopping\n",
    "\n",
    "\n",
    "dirname        = 'My_HP_trials'   \n",
    "num_max_epochs = 60    #max to train 1 model, set this something higher than expected'\n",
    "\n",
    "tuner = kt.Hyperband(build_model_hp,\n",
    "                     objective  = 'val_accuracy',\n",
    "                     max_epochs = num_max_epochs,  \n",
    "                     factor     = 3,\n",
    "                     hyperband_iterations=10,\n",
    "                     directory   =dirname, \n",
    "                     overwrite   =True,   #overwrite directory each run\n",
    "                     project_name='hyperbandtest',\n",
    "                     executions_per_trial=5,  #to try several initializations\n",
    "                     seed        =777)\n",
    "\n",
    "#this has same arguments as the model.fit function\n",
    "tunerhistory=tuner.search(X_train, Y_train, \n",
    "          validation_data=(X_test,Y_test),\n",
    "          batch_size=32, epochs=num_max_epochs, verbose=1,callbacks=[myES_function])\n",
    "        \n",
    "tuner.results_summary(5)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info, best parameters: rank hpnumfilters activation\n",
      "                0 28 relu\n",
      "                1 32 relu\n",
      "                2 16 relu\n",
      "                3 20 relu\n",
      "                4 24 relu\n"
     ]
    }
   ],
   "source": [
    "#print(\"best to worst\\n\")\n",
    "print(\"Info, best parameters: rank hpnumfilters activation\")\n",
    "for i in range(len(best_hps)):\n",
    "        print(\"               \",i,best_hps[i].get('hpnumfilters'),  \n",
    "                                best_hps[i].get('hpActivation') ) # <<<<----- add code here\n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best trial: 0006\n"
     ]
    }
   ],
   "source": [
    " for trial in tuner.oracle.get_best_trials(): #[0].trial_id\n",
    "        print('best trial:',trial.trial_id)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bracket 0 num rounds 1\n",
      "bracket 1 num rounds 2\n",
      "bracket 2 num rounds 3\n",
      "bracket 3 num rounds 4\n"
     ]
    }
   ],
   "source": [
    "for i in range(tuner.oracle._get_num_brackets()):\n",
    "   print('bracket',i,'num rounds',tuner.oracle._get_num_rounds(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
